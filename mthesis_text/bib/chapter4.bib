@article{Verikas2011,
abstract = {Random forests (RF) has become a popular technique for classification, prediction, studying variable importance, variable selection, and outlier detection. There are numerous application examples of RF in a variety of fields. Several large scale comparisons including RF have been performed. There are numerous articles, where variable importance evaluations based on the variable importance measures available from RF are used for data exploration and understanding. Apart from the literature survey in RF area, this paper also presents results of new tests regarding variable rankings based on RF variable importance measures. We studied experimentally the consistency and generality of such rankings. Results of the studies indicate that there is no evidence supporting the belief in generality of such rankings. A high variance of variable importance evaluations was observed in the case of small number of trees and small data sets. ?? 2010 Elsevier Ltd. All rights reserved.},
author = {Verikas, A. and Gelzinis, A. and Bacauskiene, M.},
doi = {10.1016/j.patcog.2010.08.011},
isbn = {0031-3203},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Classifier,Data proximity,Random forests,Variable importance,Variable selection},
number = {2},
pages = {330--349},
title = {{Mining data with random forests: A survey and results of new tests}},
volume = {44},
year = {2011}
}

@article{Bergstra2012,
abstract = {Grid search and manual search are the most widely used strategies for hyper-parameter optimiza-tion. This paper shows empirically and theoretically that randomly chosen trials are more efficient for hyper-parameter optimization than trials on a grid. Empirical evidence comes from a compar-ison with a large previous study that used grid search and manual search to configure neural net-works and deep belief networks. Compared with neural networks configured by a pure grid search, we find that random search over the same domain is able to find models that are as good or better within a small fraction of the computation time. Granting random search the same computational budget, random search finds better models by effectively searching a larger, less promising con-figuration space. Compared with deep belief networks configured by a thoughtful combination of manual search and grid search, purely random search over the same 32-dimensional configuration space found statistically equal performance on four of seven data sets, and superior performance on one of seven. A Gaussian process analysis of the function from hyper-parameters to validation set performance reveals that for most data sets only a few of the hyper-parameters really matter, but that different hyper-parameters are important on different data sets. This phenomenon makes grid search a poor choice for configuring algorithms for new data sets. Our analysis casts some light on why recent " High Throughput " methods achieve surprising success—they appear to search through a large number of hyper-parameters because most hyper-parameters do not matter much. We anticipate that growing interest in large hierarchical models will place an increasing burden on techniques for hyper-parameter optimization; this work shows that random search is a natural base-line against which to judge progress in the development of adaptive (sequential) hyper-parameter optimization algorithms.},
author = {{Bergstra}, James and {Yoshua Bengio}, Umontrealca},
isbn = {1532-4435},
issn = {1532-4435},
journal = {Journal of Machine Learning Research},
keywords = {deep learning,global optimization,model selection,neural networks,response surface modeling},
pages = {281--305},
title = {{Random Search for Hyper-Parameter Optimization}},
volume = {13},
year = {2012}
}

@book{Bishop2006,
abstract = {The dramatic growth in practical applications for machine learning over the last ten years has been accompanied by many important developments in the underlying algorithms and techniques. For example, Bayesian methods have grown from a specialist niche to become mainstream, while graphical models have emerged as a general framework for describing and applying probabilistic techniques. The practical applicability of Bayesian methods has been greatly enhanced by the development of a range of approximate inference algorithms such as variational Bayes and expectation propagation, while new models based on kernels have had a significant impact on both algorithms and applications. This completely new textbook reflects these recent developments while providing a comprehensive introduction to the fields of pattern recognition and machine learning. It is aimed at advanced undergraduates or first-year PhD students, as well as researchers and practitioners. No previous knowledge of pattern recognition or machine learning concepts is assumed. Familiarity with multivariate calculus and basic linear algebra is required, and some experience in the use of probabilities would be helpful though not essential as the book includes a self-contained introduction to basic probability theory. The book is suitable for courses on machine learning, statistics, computer science, signal processing, computer vision, data mining, and bioinformatics. Extensive support is provided for course instructors, including more than 400 exercises, graded according to difficulty. Example solutions for a subset of the exercises are available from the book web site, while solutions for the remainder can be obtained by instructors from the publisher. The book is supported by a great deal of additional material, and the reader is encouraged to visit the book web site for the latest information. A forthcoming companion volume will deal with practical aspects of pattern recognition and machine learning, and will include free software implementations of the key algorithms along with example data sets and demonstration programs. Christopher Bishop is Assistant Director at Microsoft Research Cambridge, and also holds a Chair in Computer Science at the University of Edinburgh. He is a Fellow of Darwin College Cambridge, and was recently elected Fellow of the Royal Academy of Engineering. The author's previous textbook "Neural Networks for Pattern Recognition" has been widely adopted.},
archivePrefix = {arXiv},
arxivId = {0-387-31073-8},
author = {Bishop, Christopher M},
booktitle = {Pattern Recognition},
doi = {10.1117/1.2819119},
eprint = {0-387-31073-8},
isbn = {9780387310732},
issn = {10179909},
number = {4},
pages = {738},
pmid = {8943268},
title = {{Pattern Recognition and Machine Learning}},
url = {http://www.library.wisc.edu/selectedtocs/bg0137.pdf},
volume = {4},
year = {2006}
}

@article{Cortes1995,
abstract = {Oil/water partition coefficient (log P) is one of the key points for lead compound to be drug. In silico log P models based solely on chemical structures have become an important part of modern drug discovery. Here, we report support vector machines, radial basis function neural networks, and multiple linear regression methods to investigate the correlation between partition coefficient and physico-chemical descriptors for a large data set of compounds. The correlation coefficient r (2) between experimental and predicted log P for training and test sets by support vector machines, radial basis function neural networks, and multiple linear regression is 0.92, 0.90, and 0.88, respectively. The results show that non-linear support vector machines derives statistical models that have better prediction ability than those of radial basis function neural networks and multiple linear regression methods. This indicates that support vector machines can be used as an alternative modeling tool for quantitative structure-property/activity relationships studies.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Cortes, Corinna and Vapnik, Vladimir},
doi = {10.1023/A:1022627411411},
eprint = {arXiv:1011.1669v3},
isbn = {0885-6125},
issn = {15730565},
journal = {Machine Learning},
keywords = {efficient learning algorithms,neural networks,pattern recognition,polynomial classifiers,radial basis function classifiers},
number = {3},
pages = {273--297},
pmid = {19549084},
title = {{Support-Vector Networks}},
volume = {20},
year = {1995}
}

@article{Chang2011,
abstract = {LIBSVM is a library for Support Vector Machines (SVMs). We have been actively developing this package since the year 2000. The goal is to help users to easily apply SVM to their applications. LIBSVM has gained wide popularity in machine learning and many other areas. In this article, we present all implementation details of LIBSVM. Issues such as solving SVM optimization problems, theoretical convergence, multi-class classification, probability estimates, and parameter selection are discussed in detail},
archivePrefix = {arXiv},
arxivId = {0-387-31073-8},
author = {Chang, Chih-chung and Lin, Chih-jen},
doi = {10.1145/1961189.1961199},
eprint = {0-387-31073-8},
isbn = {2157-6904},
issn = {21576904},
journal = {ACM Transactions on Intelligent Systems and Technology (TIST)},
keywords = {classification,libsvm,optimization,regression,support vector ma-},
pages = {1--39},
pmid = {371},
title = {{LIBSVM : A Library for Support Vector Machines}},
volume = {2},
year = {2011}
}

@article{Kennel2004,
abstract = {Many data-based statistical algorithms require that one find $\backslash$textit{\{}near or nearest neighbors{\}} to a given vector among a set of points in that vector space, usually with Euclidean topology. The k-d data structure and search algorithms are the generalization of classical binary search trees to higher dimensional spaces, so that one may locate near neighbors to an example vector in {\$}O(\backslashlog N){\$} time instead of the brute-force O(N) time, with {\$}N{\$} being the size of the data base. KDTREE2 is a Fortran 95 module, and a parallel set of C++ classes which implement tree construction and search routines to find either a set of {\$}m{\$} nearest neighbors to an example, or all the neighbors within some Euclidean distance {\$}r.{\$} The two versions are independent and function fully on their own. Considerable care has been taken in the implementation of the search methods, resulting in substantially higher computational efficiency (up to an order of magnitude faster) than the author's previous Internet-distributed version. Architectural improvements include rearrangement for memory cache-friendly performance, heap-based priority queues for large {\$}m{\$}searches, and more effective pruning of search paths by geometrical constraints to avoid wasted effort. The improvements are the most potent in the more difficult and slowest cases: larger data base sizes, higher dimensionality manifolds containing the data set, and larger numbers of neighbors to search for. The C++ implementation requires the Standard Template Library as well as the BOOST C++ library be installed.},
archivePrefix = {arXiv},
arxivId = {physics/0408067},
author = {Kennel, Matthew B.},
eprint = {0408067},
journal = {arXiv preprint arXiv:0408067},
primaryClass = {physics},
title = {{KDTREE 2: Fortran 95 and C++ software to efficiently search for near neighbors in a multi-dimensional Euclidean space}},
url = {http://arxiv.org/abs/physics/0408067},
year = {2004}
}

@inproceedings{Schapire1999,
abstract = {Boosting is a general method for improving the accuracy of any given learning algorithm. This short overview paper introduces the boosting algorithm AdaBoost, and explains the underlying theory of boosting, including an explanation of why boosting often does not suffer from overfitting as well as boosting's relationship to support-vector machines. Some examples of recent applications of boosting are also described.},
archivePrefix = {arXiv},
arxivId = {arXiv:1508.01136v1},
author = {Schapire, Robert E.},
booktitle = {IJCAI International Joint Conference on Artificial Intelligence},
doi = {citeulike-article-id:765005},
eprint = {arXiv:1508.01136v1},
isbn = {3540440119},
issn = {10450823},
pages = {1401--1406},
title = {{A brief introduction to boosting}},
volume = {2},
year = {1999}
}

@article{Friedman2001,
abstract = {Function estimation/approximation is viewed from the perspective of numerical optimization in function space, rather than parameter space. A connection is made between stagewise additive expansions and steepest-descent minimization. A general gradient descent "boosting" paradigm is developed for additive expansions based on any fitting criterion. Specific algorithms are presented for least-squares, least absolute deviation, and Huber-M loss functions for regression, and multiclass logistic likelihood for classification. Special enhancements are derived for the particular case where the individual additive components are regression trees, and tools for interpreting such "TreeBoost" models are presented. Gradient boosting of regression trees produces competitive, highly robust, interpretable procedures for both regression and classification, especially appropriate for ruining less than clean data. Connections between this approach and the boosting methods of Freund and Shapire and Friedman, Hastie and Tibshirani are discussed.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Friedman, Jerome H.},
doi = {DOI 10.1214/aos/1013203451},
eprint = {arXiv:1011.1669v3},
isbn = {0090-5364},
issn = {00905364},
journal = {Annals of Statistics},
keywords = {Boosting,Decision trees,Function estimation,Robust nonparametric regression},
number = {5},
pages = {1189--1232},
pmid = {21740230},
title = {{Greedy function approximation: A gradient boosting machine}},
volume = {29},
year = {2001}
}

@article{Lewis2000,
abstract = {A common goal of many clinical research studies is the development of a reliable clinical decision rule, which can be used to classify new patients into clinically-important categories. Examples of such clinical decision rules include triage rules, whether used in the out-of-hospital setting or in the emergency department, and rules used to classify patients into various risk categories so that appropriate decisions can be made regarding treatment or hospitalization. Traditional statistical methods are cumbersome to use, or of limited utility, in addressing these types of classification problems. There are a number of reasons for these difficulties. First, there are generally many possible predictor variables which makes the task of variable selection difficult. Traditional statistical methods are poorly suited for this sort of multiple comparison. Second, the predictor variables are rarely nicely distributed. Many clinical variables are not normally distributed and different groups of patients may have markedly different degrees of variation or variance. Third, complex interactions or patterns may exist in the data. For example, the value of one variable (e.g., age) may substantially affect the importance of another variable (e.g., weight). These types of interactions are generally difficult to model, and virtually impossible to model when the number of interactions and variables becomes substantial. Fourth, the results of traditional methods may be difficult to use. For example, a multivariate logistic regression model yields a probability of disease, which can be calculated using the regression coefficients and the characteristics of the patient, yet such models are rarely utilized in clinical practice. Clinicians generally do not think in terms of probability but, rather in terms of categories, such as low risk versus high risk. Regardless of the statistical methodology being used, the creation of a clinical decision rule requires a relatively large dataset. For each patient in the dataset, one variable (the dependent variable), records whether or not that patient had the condition which we hope to predict accurately in future patients. Examples might include significant injury after trauma, myocardial infarction, or subarachnoid hemorrhage in the setting of headache. In addition, other variables record the values of patient characteristics which we believe might help us to predict the value of the dependent variable. For example, if one hopes to predict the presence of subarachnoid hemorrhage, a possible predictor variable might be whether or not the patient's headache was sudden in onset; another possible predictor would be whether or not the patient has a history of similar headaches in the past. In many clinically-important settings, the number of possible predictor variables is quite large. Within the last 10 years, there has been increasing interest in the use of classification and regression tree (CART) analysis. CART analysis is a tree-building technique which is unlike traditional data analysis methods. It is ideally suited to the generation of clinical decision rules. Because CART analysis is unlike other analysis methods it has been accepted relatively slowly. Furthermore, the vast majority of statisticians have little or no experience with the technique. Other factors which limit CART's general acceptability are the complexity of the analysis and, until recently, the software required to perform CART analysis was difficult to use. Luckily, it is now possible to perform a CART analysis without a deep understanding of each of the multiple steps being completed by the software. In a number of studies, I have found CART to be quite effective for creating clinical decision rules which perform as well or better than rules developed using more traditional methods. In addition, CART is often able to uncover complex interactions between predictors which may be difficult or impossible to uncover using traditional multivariate techniques. The purpose of this lecture is to provide an overview of CART methodology, emphasizing practical use rather than the underlying statistical theory.},
author = {Lewis, Roger J and Ph, D and Street, West Carson},
doi = {10.1.1.95.4103},
journal = {2000 Annual Meeting of the Society for Academic Emergency Medicine},
number = {310},
pages = {14p},
title = {{An Introduction to Classification and Regression Tree ( CART ) Analysis}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.95.4103{\&}rep=rep1{\&}type=pdf},
year = {2000}
}


@misc{Leach2006,
abstract = {ChemInform is a weekly Abstracting Service, delivering concise information at a glance that was extracted from about 200 leading journals. To access a ChemInform Abstract, please click on HTML or PDF.},
author = {Leach, Andrew R. and Shoichet, Brian K. and Peishoff, Catherine E.},
booktitle = {Journal of Medicinal Chemistry},
doi = {10.1021/jm060999m},
isbn = {0022-2623},
issn = {00222623},
number = {20},
pages = {5851--5855},
pmid = {17004700},
title = {{Prediction of protein-ligand interactions. Docking and scoring: Successes and gaps}},
volume = {49},
year = {2006}
}


@article{Friesner2004,
abstract = {Unlike other methods for docking ligands to the rigid 3D structure of a known protein receptor, Glide approximates a complete systematic search of the conformational, orientational, and positional space of the docked ligand. In this search, an initial rough positioning and scoring phase that dramatically narrows the search space is followed by torsionally flexible energy optimization on an OPLS-AA nonbonded potential grid for a few hundred surviving candidate poses. The very best candidates are further refined via a Monte Carlo sampling of pose conformation; in some cases, this is crucial to obtaining an accurate docked pose. Selection of the best docked pose uses a model energy function that combines empirical and force-field-based terms. Docking accuracy is assessed by redocking ligands from 282 cocrystallized PDB complexes starting from conformationally optimized ligand geometries that bear no memory of the correctly docked pose. Errors in geometry for the top-ranked pose are less than 1 A in nearly half of the cases and are greater than 2 A in only about one-third of them. Comparisons to published data on rms deviations show that Glide is nearly twice as accurate as GOLD and more than twice as accurate as FlexX for ligands having up to 20 rotatable bonds. Glide is also found to be more accurate than the recently described Surflex method.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Friesner, Richard A. and Banks, Jay L. and Murphy, Robert B. and Halgren, Thomas A. and Klicic, Jasna J. and Mainz, Daniel T. and Repasky, Matthew P. and Knoll, Eric H. and Shelley, Mee and Perry, Jason K. and Shaw, David E. and Francis, Perry and Shenkin, Peter S.},
doi = {10.1021/jm0306430},
eprint = {arXiv:1011.1669v3},
isbn = {0022-2623},
issn = {00222623},
journal = {Journal of Medicinal Chemistry},
number = {7},
pages = {1739--1749},
pmid = {15027865},
title = {{Glide: A New Approach for Rapid, Accurate Docking and Scoring. 1. Method and Assessment of Docking Accuracy}},
volume = {47},
year = {2004}
}

@article{Krammer2005,
abstract = {We present two new empirical scoring functions, LigScore1 and LigScore2, that attempt to accurately predict the binding affinity between ligand molecules and their protein receptors. The LigScore functions consist of three distinct terms that describe the van der Waals interaction, the polar attraction between the ligand and protein, and the desolvation penalty attributed to the binding of the polar ligand atoms to the protein and vice versa. Utilizing a regression approach on a data set of 118 protein-ligand complexes we have obtained a linear equation, LigScore2, using these three descriptors. LigScore2 has good predictability with regard to experimental pKi values yielding a correlation coefficient, r2, of 0.75 and a standard deviation of 1.04 over the training data set, which consists of a diverse set of proteins that span more than seven protein families. ?? 2004 Elsevier Inc. All rights reserved.},
author = {Krammer, Andr{\'{e}} and Kirchhoff, Paul D. and Jiang, X. and Venkatachalam, C. M. and Waldman, Marvin},
doi = {10.1016/j.jmgm.2004.11.007},
isbn = {1093-3263 (Print)},
issn = {10933263},
journal = {Journal of Molecular Graphics and Modelling},
keywords = {Binding affinity,Desolvation penalty,LigScore},
number = {5},
pages = {395--407},
pmid = {15781182},
title = {{LigScore: A novel scoring function for predicting binding affinities}},
volume = {23},
year = {2005}
}

@article{Huang2006,
abstract = {Ligand binding affinity prediction is one of the most important applications of computational chemistry. However, accurately ranking compounds with respect to their estimated binding affinities to a biomolecular target remains highly challenging. We provide an overview of recent work using molecular mechanics energy functions to address this challenge. We briefly review methods that use molecular dynamics and Monte Carlo simulations to predict absolute and relative ligand binding free energies, as well as our own work in which we have developed a physics-based scoring method that can be applied to hundreds of thousands of compounds by invoking a number of simplifying approximations. In our previous studies, we have demonstrated that our scoring method is a promising approach for improving the discrimination between ligands that are known to bind and those that are presumed not to, in virtual screening of large compound databases. In new results presented here, we explore several improvements to our computational method including modifying the dielectric constant used for the protein and ligand interiors, and empirically scaling energy terms to compensate for deficiencies in the energy model. Future directions for further improving our physics-based scoring method are also discussed.},
author = {Huang, Niu and Kalyanaraman, Chakrapani and Bernacki, Katarzyna and Jacobson, Matthew P},
doi = {10.1039/b608269f},
issn = {1463-9076},
journal = {Physical chemistry chemical physics : PCCP},
number = {44},
pages = {5166--5177},
pmid = {17203140},
title = {{Molecular mechanics methods for predicting protein-ligand binding.}},
volume = {8},
year = {2006}
}


@article{Mooij2005,
abstract = {We present a novel atom-atom potential derived from a database of protein-ligand complexes. First, we clarify the similarities and differences between two statistical potentials described in the literature, PMF and Drugscore. We highlight shortcomings caused by an important factor unaccounted for in their reference states, and describe a new potential, which we name the Astex Statistical Potential (ASP). ASP's reference state considers the difference in exposure of protein atom types towards ligand binding sites. We show that this new potential predicts binding affinities with an accuracy similar to that of Goldscore and Chemscore. We investigate the influence of the choice of reference state by constructing two additional statistical potentials that differ from ASP only in this respect. The reference states in these two potentials are defined along the lines of Drugscore and PMF. In docking experiments, the potential using the new reference state proposed for ASP gives better success rates than when these literature reference states were used; a success rate similar to the established scoring functions Goldscore and Chemscore is achieved with ASP. This is the case both for a large, general validation set of protein-ligand structures and for small test sets of actives against four pharmaceutically relevant targets. Virtual screening experiments for these targets show less discrimination between the different reference states in terms of enrichment. In addition, we describe how statistical potentials can be used in the construction of targeted scoring functions. Examples are given for cdk2, using four different targeted scoring functions, biased towards increasingly large target-specific databases. Using these targeted scoring functions, docking success rates as well as enrichments are significantly better than for the general ASP scoring function. Results improve with the number of structures used in the construction of the target scoring functions, thus illustrating that these targeted ASP potentials can be continuously improved as new structural data become available.},
author = {Mooij, W. T M and Verdonk, Marcel L.},
doi = {10.1002/prot.20588},
isbn = {0887-3585},
issn = {08873585},
journal = {Proteins: Structure, Function and Genetics},
keywords = {Docking,Protein-ligand interactions,Statistical potentials,Targeted scoring functions,Virtual screening},
number = {2},
pages = {272--287},
pmid = {16106379},
title = {{General and targeted statistical potentials for protein-ligand interactions}},
volume = {61},
year = {2005}
}

@article{Gohlke2000,
abstract = {The development and validation of a new knowledge-based scoring function (DrugScore) to describe the binding geometry of ligands in proteins is presented. It discriminates efficiently between well-docked ligand binding modes (root-mean-square deviation {\textless}2.0 A with respect to a crystallographically determined reference complex) and those largely deviating from the native structure, e.g. generated by computer docking programs. Structural information is extracted from crystallographically determined protein-ligand complexes using ReLiBase and converted into distance-dependent pair-preferences and solvent-accessible surface (SAS) dependent singlet preferences for protein and ligand atoms. Definition of an appropriate reference state and accounting for inaccuracies inherently present in experimental data is required to achieve good predictive power. The sum of the pair preferences and the singlet preferences is calculated based on the 3D structure of protein-ligand binding modes generated by docking tools. For two test sets of 91 and 68 protein-ligand complexes, taken from the Protein Data Bank (PDB), the calculated score recognizes poses generated by FlexX deviating {\textless}2 A from the crystal structure on rank 1 in three quarters of all possible cases. Compared to FlexX, this is a substantial improvement. For ligand geometries generated by DOCK, DrugScore is superior to the "chemical scoring" implemented into this tool, while comparable results are obtained using the "energy scoring" in DOCK. None of the presently known scoring functions achieves comparable power to extract binding modes in agreement with experiment. It is fast to compute, regards implicitly solvation and entropy contributions and produces correctly the geometry of directional interactions. Small deviations in the 3D structure are tolerated and, since only contacts to non-hydrogen atoms are regarded, it is independent from assumptions of protonation states.},
author = {Gohlke, H and Hendlich, M and Klebe, G},
doi = {10.1006/jmbi.1999.3371\rS0022-2836(99)93371-5 [pii]},
isbn = {0022-2836 (Print)$\backslash$r0022-2836 (Linking)},
issn = {0022-2836},
journal = {Journal of Molecular Biology},
keywords = {*Artificial Intelligence,*Protein Binding,Ligands,Protein Conformation,Surface Properties,Thermodynamics},
number = {2},
pages = {337--356},
pmid = {10623530},
title = {{Knowledge-based scoring function to predict protein-ligand interactions}},
volume = {295},
year = {2000}
}

@incollection{Abdi2003,
abstract = {PLS regression is a recent technique that generalizes and combines features from principal component analysis and multiple regression. Its goal is to predict or analyze a set of dependent variables from a set of independent variables or predictors. This prediction is achieved by extracting from the predictors a set of orthogonal factors called latent variables which have the best predictive power.},
author = {Abdi, Herv{\'{e}}},
booktitle = {Encyclopedia for research methods for the social sciences},
doi = {http://dx.doi.org/10.4135/9781412950589.n690},
isbn = {9781412950589},
issn = {15315487},
pages = {792--795},
pmid = {20539106},
title = {{Partial Least Squares (PLS) Regression}},
year = {2003}
}

@article{Baum2010,
abstract = {Additivity of functional group contributions to protein-ligand binding is a very popular concept in medicinal chemistry as the basis of rational design and optimized lead structures. Most of the currently applied scoring functions for docking build on such additivity models. Even though the limitation of this concept is well known, case studies examining in detail why additivity fails at the molecular level are still very scarce. The present study shows, by use of crystal structure analysis and isothermal titration calorimetry for a congeneric series of thrombin inhibitors, that extensive cooperative effects between hydrophobic contacts and hydrogen bond formation are intimately coupled via dynamic properties of the formed complexes. The formation of optimal lipophilic contacts with the surface of the thrombin S3 pocket and the full desolvation of this pocket can conflict with the formation of an optimal hydrogen bond between ligand and protein. The mutual contributions of the competing interactions depend on the size of the ligand hydrophobic substituent and influence the residual mobility of ligand portions at the binding site. Analysis of the individual crystal structures and factorizing the free energy into enthalpy and entropy demonstrates that binding affinity of the ligands results from a mixture of enthalpic contributions from hydrogen bonding and hydrophobic contacts, and entropic considerations involving an increasing loss of residual mobility of the bound ligands. This complex picture of mutually competing and partially compensating enthalpic and entropic effects determines the non-additivity of free energy contributions to ligand binding at the molecular level. ?? 2010 Elsevier Ltd.},
author = {Baum, Bernhard and Muley, Laveena and Smolinski, Michael and Heine, Andreas and Hangauer, David and Klebe, Gerhard},
doi = {10.1016/j.jmb.2010.02.007},
isbn = {1089-8638},
issn = {00222836},
journal = {Journal of Molecular Biology},
keywords = {Crystal structure analysis,Isothermal titration calorimetry,Ligand-protein interactions,Non-additivity of functional group contributions,Thrombin},
number = {4},
pages = {1042--1054},
pmid = {20156458},
title = {{Non-additivity of functional group contributions in protein-ligand binding: A comprehensive study by crystallography and isothermal titration calorimetry}},
volume = {397},
year = {2010}
}

@article{Li2013,
abstract = {Scoring functions have been widely used to assess protein?ligand binding affinity in structure-based drug discovery. However, currently commonly used scoring functions face some challenges including poor correlation between calculated scores and experimental binding affinities, target-dependent performance, and low sensitivity to analogues. In this account, we propose a new empirical scoring function termed ID-Score. ID-Score was established based on a comprehensive set of descriptors related to protein?ligand interactions; these descriptors cover nine categories: van der Waals interaction, hydrogen-bonding interaction, electrostatic interaction, $\pi$-system interaction, metal?ligand bonding interaction, desolvation effect, entropic loss effect, shape matching, and surface property matching. A total of 2278 complexes were used as the training set, and a modified support vector regression (SVR) algorithm was used to fit the experimental binding affinities. Evaluation results showed that ID-Score outperformed other selected commonly used scoring functions on a benchmark test set and showed considerable performance on a large independent test set. ID-Score also showed a consistent higher performance across different biological targets. Besides, it could correctly differentiate structurally similar ligands, indicating higher sensitivity to analogues. Collectively, the better performance of ID-Score enables it as a useful tool in assessing protein?ligand binding affinity in structure-based drug discovery as well as in lead optimization.},
author = {Li, Guo Bo and Yang, Ling Ling and Wang, Wen Jing and Li, Lin Li and Yang, Sheng Yong},
doi = {10.1021/ci300493w},
isbn = {1549-9596},
issn = {15499596},
journal = {Journal of Chemical Information and Modeling},
number = {3},
pages = {592--600},
pmid = {23394072},
title = {{ID-score: A new empirical scoring function based on a comprehensive set of descriptors related to protein-ligand interactions}},
volume = {53},
year = {2013}
}

@article{Ballester2010,
abstract = {Motivation: Accurately predicting the binding affinities of large sets of diverse protein–ligand complexes is an extremely challenging task. The scoring functions that attempt such computational prediction are essential for analysing the outputs of molecular docking, which in turn is an important technique for drug discovery, chemical biology and structural biology. Each scoring function assumes a predetermined theory-inspired functional form for the relationship between the variables that characterize the complex, which also include parameters fitted to experimental or simulation data and its predicted binding affinity. The inherent problem of this rigid approach is that it leads to poor predictivity for those complexes that do not conform to the modelling assumptions. Moreover, resampling strategies, such as cross-validation or bootstrapping, are still not systematically used to guard against the overfitting of calibration data in parameter estimation for scoring functions.Results: We propose a novel scoring function (RF-Score) that circumvents the need for problematic modelling assumptions via non-parametric machine learning. In particular, Random Forest was used to implicitly capture binding effects that are hard to model explicitly. RF-Score is compared with the state of the art on the demanding PDBbind benchmark. Results show that RF-Score is a very competitive scoring function. Importantly, RF-Score's performance was shown to improve dramatically with training set size and hence the future availability of more high-quality structural and interaction data is expected to lead to improved versions of RF-Score.Contact: pedro.ballester@ebi.ac.uk; jbom@st-andrews.ac.ukSupplementary information: Supplementary data are available at Bioinformatics online.},
archivePrefix = {arXiv},
arxivId = {0-387-31073-8},
author = {Ballester, Pedro J. and Mitchell, John B O},
doi = {10.1093/bioinformatics/btq112},
eprint = {0-387-31073-8},
isbn = {0070428077},
issn = {13674803},
journal = {Bioinformatics},
number = {9},
pages = {1169--1175},
pmid = {20236947},
title = {{A machine learning approach to predicting protein-ligand binding affinity with applications to molecular docking}},
volume = {26},
year = {2010}
}

@article{Durrant2011,
abstract = {NNScore is a neural-network-based scoring function designed to aid the computational identification of small-molecule ligands. While the test cases included in the original NNScore article demonstrated the utility of the program, the application examples were limited. The purpose of the current work is to further confirm that neural-network scoring functions are effective, even when compared to the scoring functions of state-of-the-art docking programs, such as AutoDock, the most commonly cited program, and AutoDock Vina, thought to be two orders of magnitude faster. Aside from providing additional validation of the original NNScore function, we here present a second neural-network scoring function, NNScore 2.0. NNScore 2.0 considers many more binding characteristics when predicting affinity than does the original NNScore. The network output of NNScore 2.0 also differs from that of NNScore 1.0; rather than a binary classification of ligand potency, NNScore 2.0 provides a single estimate of the pK(d). To facilitate use, NNScore 2.0 has been implemented as an open-source python script. A copy can be obtained from http://www.nbcr.net/software/nnscore/ .},
author = {Durrant, Jacob D. and McCammon, J. Andrew},
doi = {10.1021/ci2003889},
file = {:home/jose/Downloads/ci2003889.pdf:pdf},
isbn = {1549-9596},
issn = {15499596},
journal = {Journal of Chemical Information and Modeling},
mendeley-groups = {ML GRIB/Binding affinity prediction},
number = {11},
pages = {2897--2903},
pmid = {22017367},
title = {{NNScore 2.0: A neural-network receptor-ligand scoring function}},
volume = {51},
year = {2011}
}


@article{Zilian2013,
abstract = {A major shortcoming of empirical scoring functions for protein-ligand complexes is the low degree of correlation between predicted and experimental binding affinities, as frequently observed not only for large and diverse data sets but also for SAR series of individual targets. Improvements can be envisaged by developing new descriptors, employing larger training sets of higher quality, and resorting to more sophisticated regression methods. Herein, we describe the use of SFCscore descriptors to develop an improved scoring function by means of a PDBbind training set of 1005 complexes in combination with random forest for regression. This provided SFCscoreRF as a new scoring function with significantly improved performance on the PDBbind and CSAR-NRC HiQ benchmarks in comparison to previously developed SFCscore functions. A leave-cluster-out cross-validation and performance in the CSAR 2012 scoring exercise point out remaining limitations but also directions for further improvements of SFCscoreRF and empirical scoring functions in general.},
author = {Zilian, David and Sotri, Christoph a},
doi = {10.1021/ci400120b},
file = {:home/jose/Downloads/ci400120b.pdf:pdf},
isbn = {1549-9596},
issn = {1549-960X},
journal = {Journal of chemical information and modeling},
mendeley-groups = {ML GRIB/Binding affinity prediction},
pages = {1923--1933},
pmid = {23705795},
title = {{SFCscoreRF: A Random Forest-Based Scoring Function for Improved A ffi nity Prediction of Protein - Ligand Complexes}},
volume = {53},
year = {2013}
}

@article{Labute2000,
abstract = {Three sets of molecular descriptors computable from connection table information are defined. These descriptors are based on atomic contributions to van der Waals surface area, log P (octanol/water), molar refractivity, and partial charge. The descriptors are applied to the construction of QSAR/QSPR models for boiling point, vapor pressure, free energy of solvation in water, solubility in water, thrombin/trypsin/factor Xa activity, blood-brain barrier permeability, and compound classification. The wide applicability of these descriptors suggests uses in QSAR/QSPR, combinatorial library design, and molecular diversity work.},
author = {Labute, Paul},
doi = {10.1016/S1093-3263(00)00068-1},
isbn = {1093-3263},
issn = {10933263},
journal = {Journal of Molecular Graphics and Modelling},
keywords = {Molecular descriptors,Molecular diversity,QSAR},
number = {4-5},
pages = {464--477},
pmid = {11143563},
title = {{A widely applicable set of descriptors}},
volume = {18},
year = {2000}
}

@article{Ballester2014,
abstract = {Predicting the binding affinities of large sets of diverse molecules against a range of macromolecular targets is an extremely challenging task. The scoring functions that attempt such computational prediction are essential for exploiting and analyzing the outputs of docking, which is in turn an important tool in problems such as structure-based drug design. Classical scoring functions assume a predetermined theory-inspired functional form for the relationship between the variables that describe an experimentally determined or modeled structure of a protein?ligand complex and its binding affinity. The inherent problem of this approach is in the difficulty of explicitly modeling the various contributions of intermolecular interactions to binding affinity. New scoring functions based on machine-learning regression models, which are able to exploit effectively much larger amounts of experimental data and circumvent the need for a predetermined functional form, have already been shown to outperform a broad range of state-of-the-art scoring functions in a widely used benchmark. Here, we investigate the impact of the chemical description of the complex on the predictive power of the resulting scoring function using a systematic battery of numerical experiments. The latter resulted in the most accurate scoring function to date on the benchmark. Strikingly, we also found that a more precise chemical description of the protein?ligand complex does not generally lead to a more accurate prediction of binding affinity. We discuss four factors that may contribute to this result: modeling assumptions, codependence of representation and regression, data restricted to the bound state, and conformational heterogeneity in data.},
author = {Ballester, Pedro J. and Schreyer, Adrian and Blundell, Tom L.},
doi = {10.1021/ci500091r},
issn = {15205142},
journal = {Journal of Chemical Information and Modeling},
number = {3},
pages = {944--955},
pmid = {24528282},
title = {{Does a more precise chemical description of protein-ligand complexes lead to more accurate prediction of binding affinity?}},
volume = {54},
year = {2014}
}

@article{Dunbar2013,
abstract = {A major goal in drug design is the improvement of computational methods for docking and scoring. The Community Structure Activity Resource (CSAR) has collected several data sets from industry and added in-house data sets that may be used for this purpose ( www.csardock.org). CSAR has currently obtained data from Abbott, GlaxoSmithKline, and Vertex and is working on obtaining data from several others. Combined with our in-house projects, we are providing a data set consisting of 6 protein targets, 647 compounds with biological affinities, and 82 crystal structures. Multiple congeneric series are available for several targets with a few representative crystal structures of each of the series. These series generally contain a few inactive compounds, usually not available in the literature, to provide an upper bound to the affinity range. The affinity ranges are typically 3-4 orders of magnitude per series. For our in-house projects, we have had compounds synthesized for biological testing. Affinities were measured by Thermofluor, Octet RED, and isothermal titration calorimetry for the most soluble. This allows the direct comparison of the biological affinities for those compounds, providing a measure of the variance in the experimental affinity. It appears that there can be considerable variance in the absolute value of the affinity, making the prediction of the absolute value ill-defined. However, the relative rankings within the methods are much better, and this fits with the observation that predicting relative ranking is a more tractable problem computationally. For those in-house compounds, we also have measured the following physical properties: logD, logP, thermodynamic solubility, and pK(a). This data set also provides a substantial decoy set for each target consisting of diverse conformations covering the entire active site for all of the 58 CSAR-quality crystal structures. The CSAR data sets (CSAR-NRC HiQ and the 2012 release) provide substantial, publically available, curated data sets for use in parametrizing and validating docking and scoring methods.},
author = {Dunbar, James B. and Smith, Richard D. and Damm-Ganamet, Kelly L. and Ahmed, Aqeel and Esposito, Emilio Xavier and Delproposto, James and Chinnaswamy, Krishnapriya and Kang, You Na and Kubish, Ginger and Gestwicki, Jason E. and Stuckey, Jeanne A. and Carlson, Heather A.},
doi = {10.1021/ci4000486},
isbn = {1549-9596},
issn = {15499596},
journal = {Journal of Chemical Information and Modeling},
number = {8},
pages = {1842--1852},
pmid = {23617227},
title = {{CSAR data set release 2012: Ligands, affinities, complexes, and docking decoys}},
volume = {53},
year = {2013}
}

@article{Wang2004,
abstract = {We have screened the entire Protein Data Bank (Release No. 103, January 2003) and identified 5671 protein-ligand complexes out of 19 621 experimental structures. A systematic examination of the primary references of these entries has led to a collection of binding affinity data (K(d), K(i), and IC(50)) for a total of 1359 complexes. The outcomes of this project have been organized into a Web-accessible database named the PDBbind database.},
author = {Wang, Renxiao and Fang, Xueliang and Lu, Yipin and Wang, Shaomeng},
doi = {10.1021/jm030580l},
isbn = {0022-2623},
issn = {00222623},
journal = {Journal of Medicinal Chemistry},
number = {12},
pages = {2977--2980},
pmid = {15163179},
title = {{The PDBbind database: Collection of binding affinities for protein-ligand complexes with known three-dimensional structures}},
volume = {47},
year = {2004}
}

@article{Doerr2016,
abstract = {Recent advances in molecular simulations have allowed scientists to investigate slower biological processes than ever before. Together with these advances came an explosion of data that has transformed a traditionally computing-bound into a data-bound problem. Here, we present HTMD, a programmable, extensible platform written in Python that aims to solve the data generation and analysis problem as well as increase reproducibility by providing a complete workspace for simulation-based discovery. So far, HTMD includes system building for CHARMM and AMBER force fields, projection methods, clustering, molecular simulation production, adaptive sampling, an Amazon cloud interface, Markov state models, and visualization. As a result, a single, short HTMD script can lead from a PDB structure to useful quantities such as relaxation time scales, equilibrium populations, metastable conformations, and kinetic rates. In this paper, we focus on the adaptive sampling and Markov state modeling features.},
author = {Doerr, S. and Harvey, M. J. and No\'e, Frank and {De Fabritiis}, G.},
doi = {10.1021/acs.jctc.6b00049},
isbn = {1549-9626 (Electronic)$\backslash$r1549-9618 (Linking)},
issn = {15499626},
journal = {Journal of Chemical Theory and Computation},
number = {4},
pages = {1845--1852},
pmid = {26949976},
title = {{HTMD: High-Throughput Molecular Dynamics for Molecular Discovery}},
volume = {12},
year = {2016}
}

@article{LeCun2015,
abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
archivePrefix = {arXiv},
arxivId = {arXiv:1312.6184v5},
author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
doi = {10.1038/nature14539},
eprint = {arXiv:1312.6184v5},
isbn = {3135786504},
issn = {0028-0836},
journal = {Nature},
number = {7553},
pages = {436--444},
pmid = {26017442},
title = {{Deep learning}},
url = {http://dx.doi.org/10.1038/nature14539},
volume = {521},
year = {2015}
}

@article{Rumelhart1986,
abstract = {We describe a new learning procedure, back-propagation, for networks of neurone-like units. The procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vecotr of the net and the desired output vector. As a result of the weight adjustments, internal 'hidden' units wich are not part of the input or output come to represent important features of the task domain, and the regularities in the task are captured by the interactions of these units. The ability to create useful new features distinguishes back-propagation from earlier, simpoler methods such as the perceptron-convergence procedure.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
doi = {10.1038/323533a0},
eprint = {arXiv:1011.1669v3},
isbn = {0262661160},
issn = {0028-0836},
journal = {Nature},
number = {6088},
pages = {533--536},
pmid = {134},
title = {{Learning representations by back-propagating errors}},
volume = {323},
year = {1986}
}


@article{Bottou2003,
abstract = {This contribution presents an overview of the theoretical and practical aspects of the broad family of learning algorithms based on Stochastic Gradient Descent, including Perceptrons, Adalines, K-Means, LVQ, Multi-Layer Networks, and Graph Transformer Networks.},
author = {Bottou, Leon},
doi = {10.1007/978-3-540-28650-9_7},
isbn = {978-3-540-23122-6},
issn = {00335533},
journal = {Learning},
keywords = {stochastic gradient descent,stochastic learning},
pages = {22},
title = {{Stochastic Learning}},
url = {http://www.cs.nyu.edu/courses/fall10/G22.2965-001/stocgraddescent.pdf},
year = {2003}
}


@misc{Jubb2015,
abstract = {The transient assembly of multiprotein complexes mediates many aspects of cell regulation and signalling in living organisms. Modulation of the formation of these complexes through targeting protein-protein interfaces can offer greater selectivity than the inhibition of protein kinases, proteases or other post-translational regulatory enzymes using substrate, co-factor or transition state mimetics. However, capitalising on protein-protein interaction interfaces as drug targets has been hindered by the nature of interfaces that tend to offer binding sites lacking the well-defined large cavities of classical drug targets. In this review we posit that interfaces formed by concerted folding and binding (disorder-to-order transitions on binding) of one partner and other examples of interfaces where a protein partner is bound through a continuous epitope from a surface-exposed helix, flexible loop or chain extension may be more tractable for the development of "orthosteric", competitive chemical modulators; these interfaces tend to offer small-volume but deep pockets and/or larger grooves that may be bound tightly by small chemical entities. We discuss examples of such protein-protein interaction interfaces for which successful chemical modulators are being developed.},
author = {Jubb, Harry and Blundell, Tom L. and Ascher, David B.},
booktitle = {Progress in Biophysics and Molecular Biology},
doi = {10.1016/j.pbiomolbio.2015.01.009},
issn = {00796107},
keywords = {Hotspots,Inhibitors druggability,Protein-protein interfaces},
number = {1},
pages = {2--9},
pmid = {25662442},
title = {{Flexibility and small pockets at protein-protein interfaces: New insights into druggability}},
volume = {119},
year = {2015}
}


@misc{Shi2014,
abstract = {Since determination of the myoglobin structure in 1957, X-ray crystallography, as the anchoring tool of structural biology, has played an instrumental role in deciphering the secrets of life. Knowledge gained through X-ray crystallography has fundamentally advanced our views on cellular processes and greatly facilitated development of modern medicine. In this brief narrative, I describe my personal understanding of the evolution of structural biology through X-ray crystallography - using as examples mechanistic understanding of protein kinases and integral membrane proteins - and comment on the impact of technological development and outlook of X-ray crystallography.},
author = {Shi, Yigong},
booktitle = {Cell},
doi = {10.1016/j.cell.2014.10.051},
isbn = {1097-4172 (Electronic)$\backslash$r0092-8674 (Linking)},
issn = {10974172},
number = {5},
pages = {995--1014},
pmid = {25416941},
title = {{A glimpse of structural biology through X-ray crystallography}},
volume = {159},
year = {2014}
}



@article{Gobl2014,
abstract = {NMR spectroscopy is a key method for studying the structure and dynamics of (large) multidomain proteins and complexes in solution. It plays a unique role in integrated structural biology approaches as especially information about conformational dynamics can be readily obtained at residue resolution. Here, we review NMR techniques for such studies focusing on state-of-the-art tools and practical aspects. An efficient approach for determining the quaternary structure of multidomain complexes starts from the structures of individual domains or subunits. The arrangement of the domains/subunits within the complex is then defined based on NMR measurements that provide information about the domain interfaces combined with (long-range) distance and orientational restraints. Aspects discussed include sample preparation, specific isotope labeling and spin labeling; determination of binding interfaces and domain/subunit arrangements from chemical shift perturbations (CSP), nuclear Overhauser effects (NOEs), isotope editing/filtering, cross-saturation, and differential line broadening; and based on paramagnetic relaxation enhancements (PRE) using covalent and soluble spin labels. Finally, the utility of complementary methods such as small-angle X-ray or neutron scattering (SAXS, SANS), electron paramagnetic resonance (EPR) or fluorescence spectroscopy techniques is discussed. The applications of NMR techniques are illustrated with studies of challenging (high molecular weight) protein complexes. ?? 2014 Elsevier B.V. All rights reserved.},
author = {Gobl, Christoph and Madl, Tobias and Simon, Bernd and Sattler, Michael},
doi = {10.1016/j.pnmrs.2014.05.003},
isbn = {1873-3301 (Electronic){\$}\backslash{\$}r0079-6565 (Linking)},
issn = {00796565},
journal = {Progress in Nuclear Magnetic Resonance Spectroscopy},
pages = {26--63},
pmid = {24924266},
title = {{NMR approaches for structural analysis of multidomain proteins and complexes in solution}},
volume = {80},
year = {2014}
}

@article{Jordan2012,
abstract = {BACKGROUND: Identification of the residues in protein-protein interaction sites has a significant impact in problems such as drug discovery. Motivated by the observation that the set of interface residues of a protein tend to be conserved even among remote structural homologs, we introduce PrISE, a family of local structural similarity-based computational methods for predicting protein-protein interface residues.$\backslash$n$\backslash$nRESULTS: We present a novel representation of the surface residues of a protein in the form of structural elements. Each structural element consists of a central residue and its surface neighbors. The PrISE family of interface prediction methods uses a representation of structural elements that captures the atomic composition and accessible surface area of the residues that make up each structural element. Each of the members of the PrISE methods identifies for each structural element in the query protein, a collection of similar structural elements in its repository of structural elements and weights them according to their similarity with the structural element of the query protein. PrISEL relies on the similarity between structural elements (i.e. local structural similarity). PrISEG relies on the similarity between protein surfaces (i.e. general structural similarity). PrISEC, combines local structural similarity and general structural similarity to predict interface residues. These predictors label the central residue of a structural element in a query protein as an interface residue if a weighted majority of the structural elements that are similar to it are interface residues, and as a non-interface residue otherwise. The results of our experiments using three representative benchmark datasets show that the PrISEC outperforms PrISEL and PrISEG; and that PrISEC is highly competitive with state-of-the-art structure-based methods for predicting protein-protein interface residues. Our comparison of PrISEC with PredUs, a recently developed method for predicting interface residues of a query protein based on the known interface residues of its (global) structural homologs, shows that performance superior or comparable to that of PredUs can be obtained using only local surface structural similarity. PrISEC is available as a Web server at http://prise.cs.iastate.edu/$\backslash$n$\backslash$nCONCLUSIONS: Local surface structural similarity based methods offer a simple, efficient, and effective approach to predict protein-protein interface residues.},
author = {Jordan, Rafael a and EL-Manzalawy, Yasser and Dobbs, Drena and Honavar, Vasant},
doi = {10.1186/1471-2105-13-41},
isbn = {1471-2105 (Electronic)$\backslash$r1471-2105 (Linking)},
issn = {1471-2105},
journal = {BMC Bioinformatics},
number = {1},
pages = {41},
pmid = {22424103},
title = {{Predicting protein-protein interface residues using local surface structural similarity}},
url = {http://www.biomedcentral.com/1471-2105/13/41},
volume = {13},
year = {2012}
}

@article{Xue2011,
abstract = {BACKGROUND: Although homology-based methods are among the most widely used methods for predicting the structure and function of proteins, the question as to whether interface sequence conservation can be effectively exploited in predicting protein-protein interfaces has been a subject of debate. RESULTS: We studied more than 300,000 pair-wise alignments of protein sequences from structurally characterized protein complexes, including both obligate and transient complexes. We identified sequence similarity criteria required for accurate homology-based inference of interface residues in a query protein sequence.Based on these analyses, we developed HomPPI, a class of sequence homology-based methods for predicting protein-protein interface residues. We present two variants of HomPPI: (i) NPS-HomPPI (Non partner-specific HomPPI), which can be used to predict interface residues of a query protein in the absence of knowledge of the interaction partner; and (ii) PS-HomPPI (Partner-specific HomPPI), which can be used to predict the interface residues of a query protein with a specific target protein.Our experiments on a benchmark dataset of obligate homodimeric complexes show that NPS-HomPPI can reliably predict protein-protein interface residues in a given protein, with an average correlation coefficient (CC) of 0.76, sensitivity of 0.83, and specificity of 0.78, when sequence homologs of the query protein can be reliably identified. NPS-HomPPI also reliably predicts the interface residues of intrinsically disordered proteins. Our experiments suggest that NPS-HomPPI is competitive with several state-of-the-art interface prediction servers including those that exploit the structure of the query proteins. The partner-specific classifier, PS-HomPPI can, on a large dataset of transient complexes, predict the interface residues of a query protein with a specific target, with a CC of 0.65, sensitivity of 0.69, and specificity of 0.70, when homologs of both the query and the target can be reliably identified. The HomPPI web server is available at http://homppi.cs.iastate.edu/. CONCLUSIONS: Sequence homology-based methods offer a class of computationally efficient and reliable approaches for predicting the protein-protein interface residues that participate in either obligate or transient interactions. For query proteins involved in transient interactions, the reliability of interface residue prediction can be improved by exploiting knowledge of putative interaction partners.},
author = {Xue, Li C and Dobbs, Drena and Honavar, Vasant},
doi = {10.1186/1471-2105-12-244},
isbn = {1471-2105},
issn = {1471-2105},
journal = {BMC bioinformatics},
keywords = {Algorithms,Amino Acid Sequence,Humans,Protein,Protein: methods,Proteins,Proteins: chemistry,Proteins: metabolism,Sequence Analysis,Sequence Homology,Software},
pages = {244},
pmid = {21682895},
title = {{HomPPI: a class of sequence homology based protein-protein interface prediction methods.}},
volume = {12},
year = {2011}
}

@misc{Vakser2014,
abstract = {The protein-protein docking problem is one of the focal points of activity in computational biophysics and structural biology. The three-dimensional structure of a protein-protein complex, generally, is more difficult to determine experimentally than the structure of an individual protein. Adequate computational techniques to model protein interactions are important because of the growing number of known protein structures, particularly in the context of structural genomics. Docking offers tools for fundamental studies of protein interactions and provides a structural basis for drug design. Protein-protein docking is the prediction of the structure of the complex, given the structures of the individual proteins. In the heart of the docking methodology is the notion of steric and physicochemical complementarity at the protein-protein interface. Originally, mostly high-resolution, experimentally determined (primarily by x-ray crystallography) protein structures were considered for docking. However, more recently, the focus has been shifting toward lower-resolution modeled structures. Docking approaches have to deal with the conformational changes between unbound and bound structures, as well as the inaccuracies of the interacting modeled structures, often in a high-throughput mode needed for modeling of large networks of protein interactions. The growing number of docking developers is engaged in the community-wide assessments of predictive methodologies. The development of more powerful and adequate docking approaches is facilitated by rapidly expanding information and data resources, growing computational capabilities, and a deeper understanding of the fundamental principles of protein interactions.},
author = {Vakser, Ilya A.},
booktitle = {Biophysical Journal},
doi = {10.1016/j.bpj.2014.08.033},
isbn = {00063495},
issn = {15420086},
number = {8},
pages = {1785--1793},
pmid = {25418159},
title = {{Protein-protein docking: From interaction to interactome}},
volume = {107},
year = {2014}
}


@article{Hopf2014,
abstract = {Protein-protein interactions are fundamental to many biological processes. Experimental screens have identified tens of thousands of interactions, and structural biology has provided detailed functional insight for select 3D protein complexes. An alternative rich source of information about protein interactions is the evolutionary sequence record. Building on earlier work, we show that analysis of correlated evolutionary sequence changes across proteins identifies residues that are close in space with sufficient accuracy to determine the three-dimensional structure of the protein complexes. We evaluate prediction performance in blinded tests on 76 complexes of known 3D structure, predict protein-protein contacts in 32 complexes of unknown structure, and demonstrate how evolutionary couplings can be used to distinguish between interacting and non-interacting protein pairs in a large complex. With the current growth of sequences, we expect that the method can be generalized to genome-wide elucidation of protein-protein interaction networks and used for interaction predictions at residue resolution.},
archivePrefix = {arXiv},
arxivId = {1405.0929},
author = {Hopf, Thomas A. and Scharfe, Charlotta P I and Rodrigues, Jo??o P G L M and Green, Anna G. and Kohlbacher, Oliver and Sander, Chris and Bonvin, Alexandre M J J and Marks, Debora S.},
doi = {10.7554/eLife.03430},
eprint = {1405.0929},
isbn = {2050-084X (Electronic)$\backslash$r2050-084X (Linking)},
issn = {2050084X},
journal = {eLife},
keywords = {E. coli,co-evolution,evolutionary biology,genomics,interactions,protein},
pmid = {25255213},
title = {{Sequence co-evolution gives 3D contacts and structures of protein complexes}},
volume = {3},
year = {2014}
}

@article{Tien2013,
abstract = {The relative solvent accessibility (RSA) of a residue in a protein measures the extent of burial or exposure of that residue in the 3D structure. RSA is frequently used to describe a protein's biophysical or evolutionary properties. To calculate RSA, a residue's solvent accessibility (ASA) needs to be normalized by a suitable reference value for the given amino acid; several normalization scales have previously been proposed. However, these scales do not provide tight upper bounds on ASA values frequently observed in empirical crystal structures. Instead, they underestimate the largest allowed ASA values, by up to 20{\%}. As a result, many empirical crystal structures contain residues that seem to have RSA values in excess of one. Here, we derive a new normalization scale that does provide a tight upper bound on observed ASA values. We pursue two complementary strategies, one based on extensive analysis of empirical structures and one based on systematic enumeration of biophysically allowed tripeptides. Both approaches yield congruent results that consistently exceed published values. We conclude that previously published ASA normalization values were too small, primarily because the conformations that maximize ASA had not been correctly identified. As an application of our results, we show that empirically derived hydrophobicity scales are sensitive to accurate RSA calculation, and we derive new hydrophobicity scales that show increased correlation with experimentally measured scales.},
archivePrefix = {arXiv},
arxivId = {arXiv:1211.4251v3},
author = {Tien, Matthew Z. and Meyer, Austin G. and Sydykova, Dariya K. and Spielman, Stephanie J. and Wilke, Claus O.},
doi = {10.1371/journal.pone.0080635},
eprint = {arXiv:1211.4251v3},
issn = {19326203},
journal = {PLoS ONE},
number = {11},
pmid = {24278298},
title = {{Maximum allowed solvent accessibilites of residues in proteins}},
volume = {8},
year = {2013}
}


@inproceedings{Porollo2007,
abstract = {The recognition of protein interaction sites is an important intermediate step toward identification of functionally relevant residues and understanding protein function, facilitating experimental efforts in that regard. Toward that goal, the authors propose a novel representation for the recognition of protein–protein interaction sites that integrates enhanced relative solvent accessibility (RSA) predictions with high resolution structural data. An observation that RSA predictions are biased toward the level of surface exposure consistent with protein complexes led the authors to investigate the difference between the predicted and actual (i.e., observed in an unbound structure) RSA of an amino acid residue as a fingerprint of interaction sites. The authors demonstrate that RSA prediction-based fingerprints of protein interactions significantly improve the discrimination between interacting and noninteracting sites, compared with evolutionary conservation, physicochemical characteristics, structure-derived and other features considered before. On the basis of these observations, the authors developed a new method for the prediction of protein–protein interaction sites, using machine learning approaches to combine the most informative features into the final predictor. For training and validation, the authors used several large sets of protein complexes and derived from them nonredundant representative chains, with interaction sites mapped from multiple complexes. Alternative machine learning techniques are used, including Support Vector Machines and Neural Networks, so as to evaluate the relative effects of the choice of a representation and a specific learning algorithm. The effects of induced fit and uncertainty of the negative (noninteracting) class assignment are also evaluated. Several representative methods from the literature are reimplemented to enable direct comparison of the results. Using rigorous validation protocols, the authors estimated that the new method yields the overall classification accuracy of about 74{\%} and Matthews correlation coefficients of 0.42, as opposed to up to 70{\%} classification accuracy and up to 0.3 Matthews correlation coefficient for methods that do not utilize RSA prediction-based fingerprints. The new method is available at http://sppider.cchmc.org.},
archivePrefix = {arXiv},
arxivId = {q-bio/0605018},
author = {Porollo, Aleksey and Meller, Jaros{\l}aw},
booktitle = {Proteins: Structure, Function and Genetics},
doi = {10.1002/prot.21248},
eprint = {0605018},
isbn = {0887-3585},
issn = {08873585},
keywords = {Interaction sites,Machine learning,Protein complexes,Protein-protein interactions,Relative solvent accessibility,SPPIDER},
number = {3},
pages = {630--645},
pmid = {17705269},
primaryClass = {q-bio},
title = {{Prediction-based fingerprints of protein-protein interactions}},
volume = {66},
year = {2007}
}

@article{Liang2006,
abstract = {Most biological processes are mediated by interactions between proteins and their interacting partners including proteins, nucleic acids and small molecules. This work establishes a method called PINUP for binding site prediction of monomeric proteins. With only two weight parameters to optimize, PINUP produces not only 42.2{\%} coverage of actual interfaces (percentage of correctly predicted interface residues in actual interface residues) but also 44.5{\%} accuracy in predicted interfaces (percentage of correctly predicted interface residues in the predicted interface residues) in a cross validation using a 57-protein dataset. By comparison, the expected accuracy via random prediction (percentage of actual interface residues in surface residues) is only 15{\%}. The binding sites of the 57-protein set are found to be easier to predict than that of an independent test set of 68 proteins. The average coverage and accuracy for this independent test set are 30.5 and 29.4{\%}, respectively. The significant gain of PINUP over expected random prediction is attributed to (i) effective residue-energy score and accessible-surface-area-dependent interface-propensity, (ii) isolation of functional constraints contained in the conservation score from the structural constraints through the combination of residue-energy score (for structural constraints) and conservation score and (iii) a consensus region built on top-ranked initial patches.},
author = {Liang, Shide and Zhang, Chi and Liu, Song and Zhou, Yaoqi},
doi = {10.1093/nar/gkl454},
issn = {03051048},
journal = {Nucleic Acids Research},
number = {13},
pages = {3698--3707},
pmid = {16893954},
title = {{Protein binding site prediction using an empirical scoring function}},
volume = {34},
year = {2006}
}

@article{Neuvirth2004,
abstract = {Is the whole protein surface available for interaction with other proteins, or are specific sites pre-assigned according to their biophysical and structural character? And if so, is it possible to predict the location of the binding site from the surface properties? These questions are answered quantitatively by probing the surfaces of proteins using spheres of radius of 10?? on a database (DB) of 57 unique, non-homologous proteins involved in heteromeric, transient protein-protein interactions for which the structures of both the unbound and bound states were determined. In structural terms, we found the binding site to have a preference for ??-sheets and for relatively long non-structured chains, but not for ??-helices. Chemically, aromatic side-chains show a clear preference for binding sites. While the hydrophobic and polar content of the interface is similar to the rest of the surface, hydrophobic and polar residues tend to cluster in interfaces. In the crystal, the binding site has more bound water molecules surrounding it, and a lower B-factor already in the unbound protein. The same biophysical properties were found to hold for the unbound and bound DBs. All the significant interface properties were combined into ProMate, an interface prediction program. This was followed by an optimization step to choose the best combination of properties, as many of them are correlated. During optimization and prediction, the tested proteins were not used for data collection, to avoid over-fitting. The prediction algorithm is fully automated, and is used to predict the location of potential binding sites on unbound proteins with known structures. The algorithm is able to successfully predict the location of the interface for about 70{\%} of the proteins. The success rate of the predictor was equal whether applied on the unbound DB or on the disjoint bound DB. A prediction is assumed correct if over half of the predicted continuous interface patch is indeed interface. The ability to predict the location of protein-protein interfaces has far reaching implications both towards our understanding of specificity and kinetics of binding, as well as in assisting in the analysis of the proteome. ?? 2004 Elsevier Ltd. All rights reserved.},
author = {Neuvirth, Hani and Raz, Ran and Schreiber, Gideon},
doi = {10.1016/j.jmb.2004.02.040},
isbn = {0022-2836},
issn = {00222836},
journal = {Journal of Molecular Biology},
keywords = {AA, amino acids,ASA, accessible surface area,Binding-site prediction,Bioinformatics,DB, database,MS, molecular surface,NR2St, non-regular secondary structures length,Protein-protein interactions,TF, temperature factor,Transient hetero-complexes},
number = {1},
pages = {181--199},
pmid = {15050833},
title = {{ProMate: A structure based prediction program to identify the location of protein-protein binding sites}},
volume = {338},
year = {2004}
}

@article{Kufareva2007,
abstract = {Recent advances in structural proteomics call for development of fast and reliable automatic methods for prediction of functional surfaces of proteins with known three-dimensional structure, including binding sites for known and unknown protein partners as well as oligomerization interfaces. Despite significant progress the problem is still far from being solved. Most existing methods rely, at least partially, on evolutionary information from multiple sequence alignments projected on protein surface. The common drawback of such methods is their limited applicability to the proteins with a sparse set of sequential homologs, as well as inability to detect interfaces in evolutionary variable regions. In this study, the authors developed an improved method for predicting interfaces from a single protein structure, which is based on local statistical properties of the protein surface derived at the level of atomic groups. The proposed Protein IntErface Recognition (PIER) method achieved the overall precision of 60{\%} at the recall threshold of 50{\%} at the residue level on a diverse benchmark of 490 homodimeric, 62 heterodimeric, and 196 transient interfaces (compared with 25{\%} precision at 50{\%} recall expected from random residue function assignment). For 70{\%} of proteins in the benchmark, the binding patch residues were successfully detected with precision exceeding 50{\%} at 50{\%} recall. The calculation only took seconds for an average 300-residue protein. The authors demonstrated that adding the evolutionary conservation signal only marginally influenced the overall prediction performance on the benchmark; moreover, for certain classes of proteins, using this signal actually resulted in a deteriorated prediction. Thorough benchmarking using other datasets from literature showed that PIER yielded improved performance as compared with several alignment-free or alignment-dependent predictions. The accuracy, efficiency, and dependence on structure alone make PIER a suitable tool for automated high-throughput annotation of protein structures emerging from structural proteomics projects.},
archivePrefix = {arXiv},
arxivId = {q-bio/0605018},
author = {Kufareva, Irina and Budagyan, Levon and Raush, Eugene and Totrov, Maxim and Abagyan, Ruben},
doi = {10.1002/prot.21233},
eprint = {0605018},
isbn = {0887-3585},
issn = {08873585},
journal = {Proteins: Structure, Function and Genetics},
keywords = {Alignment-independent interface prediction,Cell signaling and protein recognition,Protein-protein interaction,Structural proteomics,Structure-function annotation},
number = {2},
pages = {400--417},
pmid = {17299750},
primaryClass = {q-bio},
title = {{PIER: Protein interface recognition for structural proteomics}},
volume = {67},
year = {2007}
}

@article{AfsarMinhas2014,
abstract = {We present a novel partner-specific protein-protein interaction site prediction method called PAIRpred. Unlike most existing machine learning binding site prediction methods, PAIRpred uses information from both proteins in a protein complex to generate predict pairs of interacting residues from the two proteins. PAIRpred captures sequence and structure information about residue pairs through pairwise kernels that are used for training a support vector machine classifier. As a result, PAIRpred presents a more detailed model of protein binding, and offers state of the art accuracy in predicting binding sites at the protein level as well as inter-protein residue contacts at the complex level. We demonstrate PAIRpred's performance on Docking Benchmark 4.0 and recent CAPRI targets. We present a detailed performance analysis outlining the contribution of different sequence and structure features, together with a comparison to a variety of existing interface prediction techniques. We have also studied the impact of binding- associated conformational change on prediction accuracy and found PAIRpred to be more robust to such structural changes than existing schemes. As an illustration of potential applications of PAIRpred, we provide a case study in which PAIRpred is used to analyze the nature and specificity of the interface in the interaction of human ISG15 protein with NS1 protein from influenza A virus. Python code for PAIRpred is available at: http://combi.cs.colostate.edu/ supplements/pairpred/.},
author = {{Afsar Minhas}, Fayyaz ul Amir and Geiss, Brian J. and Ben-Hur, Asa},
doi = {10.1002/prot.24479},
isbn = {0887-3585},
issn = {10970134},
journal = {Proteins: Structure, Function and Bioinformatics},
keywords = {Protein binding site prediction,Protein interface prediction},
number = {7},
pages = {1142--1155},
pmid = {24243399},
title = {{PAIRpred: Partner-specific prediction of interacting residues from sequence and structure}},
volume = {82},
year = {2014}
}


@article{Jones1997,
abstract = {Protein-protein interaction sites in complexes of known structure are characterised using a series of parameters to evaluate what differentiates them from other sites on the protein surface. Surface patches are defined in protomers from a data set of 28 homo-dimers, 20 different hetero-complexes (segregated into large and small protomers), and antigens from six antibody-antigen complexes. Six parameters (solvation potential, residue interface propensity, hydrophobicity, planarity, protrusion and accessible surface area) are calculated for the observed interface patch and all other surface patches defined on each protein. A ranking of the observed interface, relative to all other possible patches, is calculated. With this approach it becomes possible to analyse the distribution of the rankings of all the observed patches, relative to all other surface patches, for each data set. For each type of complex, none of the parameters were definitive, but the majority showed trends for the observed interface to be distinguished from other surface patches.},
author = {Jones, Susan and Thornton, Janet M.},
doi = {10.1006/jmbi.1997.1234},
isbn = {0022-2836 (Print)$\backslash$n0022-2836 (Linking)},
issn = {00222836},
journal = {Journal of Molecular Biology},
keywords = {Animals,Antigens,Antigens: chemistry,Antigens: metabolism,Binding Sites,Chemical,Dimerization,Humans,Models,Protein Binding,Proteins,Proteins: chemistry,Proteins: metabolism,Surface Properties,complex,enzyme-inhibitor complex,hetero-,homo-dimer,protein-protein interactions,surface patch},
number = {1},
pages = {121--132},
pmid = {9299342},
title = {{Analysis of protein-protein interaction sites using surface patches.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9299342$\backslash$nhttp://linkinghub.elsevier.com/retrieve/pii/S0022283697912341},
volume = {272},
year = {1997}
}

@article{Cukuroglu2014,
abstract = {Improvements in experimental techniques increasingly provide structural data relating to protein-protein interactions. Classification of structural details of protein-protein interactions can provide valuable insights for modeling and abstracting design principles. Here, we aim to cluster protein-protein interactions by their interface structures, and to exploit these clusters to obtain and study shared and distinct protein binding sites. We find that there are 22604 unique interface structures in the PDB. These unique interfaces, which provide a rich resource of structural data of protein-protein interactions, can be used for template-based docking. We test the specificity of these non-redundant unique interface structures by finding protein pairs which have multiple binding sites. We suggest that residues with more than 40{\%} relative accessible surface area should be considered as surface residues in template-based docking studies. This comprehensive study of protein interface structures can serve as a resource for the community. The dataset can be accessed at http://prism.ccbb.ku.edu.tr/piface.},
author = {Cukuroglu, Engin and Gursoy, Attila and Nussinov, Ruth and Keskin, Ozlem},
doi = {10.1371/journal.pone.0086738},
isbn = {1932-6203 (Electronic)$\backslash$r1932-6203 (Linking)},
issn = {19326203},
journal = {PLoS ONE},
number = {1},
pmid = {24475173},
title = {{Non-redundant unique interface structures as templates for modeling protein interactions}},
volume = {9},
year = {2014}
}


@inproceedings{Wallace2011,
abstract = {Class imbalance (i.e., scenarios in which classes are unequally represented in the training data) occurs in many real-world learning tasks. Yet despite its practical importance, there is no established theory of class imbalance, and existing methods for handling it are therefore not well motivated. In this work, we approach the problem of imbalance from a probabilistic perspective, and from this vantage identify dataset characteristics (such as dimensionality, sparsity, etc.) that exacerbate the problem. Motivated by this theory, we advocate the approach of bagging an ensemble of classifiers induced over balanced bootstrap training samples, arguing that this strategy will often succeed where others fail. Thus in addition to providing a theoretical understanding of class imbalance, corroborated by our experiments on both simulated and real datasets, we provide practical guidance for the data mining practitioner working with imbalanced data.},
author = {Wallace, Byron C. and Small, Kevin and Brodley, Carla E. and Trikalinos, Thomas A.},
booktitle = {Proceedings - IEEE International Conference on Data Mining, ICDM},
doi = {10.1109/ICDM.2011.33},
isbn = {9780769544083},
issn = {15504786},
keywords = {Class imbalance,Classification},
pages = {754--763},
title = {{Class imbalance, redux}},
year = {2011}
}

@article{Longadge2013,
abstract = {In last few years there are major changes and evolution has been done on classification of data. As the application area of technology is increases the size of data also increases. Classification of data becomes difficult because of unbounded size and imbalance nature of data. Class imbalance problem become greatest issue in data mining. Imbalance problem occur where one of the two classes having more sample than other classes. The most of algorithm are more focusing on classification of major sample while ignoring or misclassifying minority sample. The minority samples are those that rarely occur but very important. There are different methods available for classification of imbalance data set which is divided into three main categories, the algorithmic approach, data- preprocessing approach and feature selection approach. Each of this technique has their own advantages and disadvantages. In this paper systematic study of each approach is define which gives the right direction for research in class imbalance problem.},
archivePrefix = {arXiv},
arxivId = {1305.1707},
author = {Longadge, Rushi and Dongre, S Snehlata and Malik, Latesh},
doi = {10.1109/SIU.2013.6531574},
eprint = {1305.1707},
isbn = {978-1-4673-5563-6},
issn = {2277-5420},
journal = {International Journal of Computer Science and Network},
keywords = {class imbalance problem,data,imbalance,rare class mining,skewed data},
number = {1},
pages = {83--87},
title = {{Class imbalance problem in data mining: review}},
volume = {2},
year = {2013}
}

@article{Morris2009,
abstract = {We describe the testing and release of AutoDock4 and the accompanying graphical user interface AutoDockTools. AutoDock4 incorporates limited flexibility in the receptor. Several tests are reported here, including a redocking experiment with 188 diverse ligand-protein complexes and a cross-docking experiment using flexible sidechains in 87 HIV protease complexes. We also report its utility in analysis of covalently bound ligands, using both a grid-based docking method and a modification of the flexible sidechain technique.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Morris, Garrett M. and Ruth, Huey and Lindstrom, William and Sanner, Michel F. and Belew, Richard K. and Goodsell, David S. and Olson, Arthur J.},
doi = {10.1002/jcc.21256},
eprint = {NIHMS150003},
isbn = {1096-987X},
issn = {01928651},
journal = {Journal of Computational Chemistry},
keywords = {Autodock,Computational docking,Computer-aided drug design,Covalent ligands,Protein flexibility},
number = {16},
pages = {2785--2791},
pmid = {19399780},
title = {{Software news and updates AutoDock4 and AutoDockTools4: Automated docking with selective receptor flexibility}},
volume = {30},
year = {2009}
}


@article{Doerr2016,
abstract = {Recent advances in molecular simulations have allowed scientists to investigate slower biological processes than ever before. Together with these advances came an explosion of data that has transformed a traditionally computing-bound into a data-bound problem. Here, we present HTMD, a programmable, extensible platform written in Python that aims to solve the data generation and analysis problem as well as increase reproducibility by providing a complete workspace for simulation-based discovery. So far, HTMD includes system building for CHARMM and AMBER force fields, projection methods, clustering, molecular simulation production, adaptive sampling, an Amazon cloud interface, Markov state models, and visualization. As a result, a single, short HTMD script can lead from a PDB structure to useful quantities such as relaxation time scales, equilibrium populations, metastable conformations, and kinetic rates. In this paper, we focus on the adaptive sampling and Markov state modeling features.},
author = {Doerr, S. and Harvey, M. J. and No??, Frank and {De Fabritiis}, G.},
doi = {10.1021/acs.jctc.6b00049},
isbn = {1549-9626 (Electronic)$\backslash$r1549-9618 (Linking)},
issn = {15499626},
journal = {Journal of Chemical Theory and Computation},
number = {4},
pages = {1845--1852},
pmid = {26949976},
title = {{HTMD: High-Throughput Molecular Dynamics for Molecular Discovery}},
volume = {12},
year = {2016}
}

@inproceedings{Michalski1986,
abstract = {This research was supported in part by the National Science Foundation under Grant No. DCR 84-06801, the Office of Naval Research under Grant No. N00014-82-K-0186, the Defense Advanced Research Project Agency under Grant No. N00014-K-85-0878, and by the Slovene Research Council.},
author = {Michalski, Ryszard S. and Mozetic, I. and Hong, J.},
booktitle = {Proceedings of IMAL 1986},
pages = {36},
pmid = {2905919},
title = {{The AQ15 Inductive Learning System: an Overview and Experiments}},
year = {1986}
}

@misc{Lichman2013 ,
author = "M. Lichman",
year = "2013",
title = "{UCI} Machine Learning Repository",
url = "http://archive.ics.uci.edu/ml",
institution = "University of California, Irvine, School of Information and Computer Sciences" }

@article{Tsanas2014,
abstract = {Vocal performance degradation is a common symptom for the vast majority of Parkinson's disease (PD) subjects, who typically follow personalized one-to-one periodic rehabilitation meetings with speech experts over a long-term period. Recently, a novel computer program called Lee Silverman voice treatment (LSVT) Companion was developed to allow PD subjects to independently progress through a rehabilitative treatment session. This study is part of the assessment of the LSVT Companion, aiming to investigate the potential of using sustained vowel phonations towards objectively and automatically replicating the speech experts' assessments of PD subjects' voices as “acceptable” (a clinician would allow persisting during in-person rehabilitation treatment) or “unacceptable” (a clinician would not allow persisting during in-person rehabilitation treatment). We characterize each of the 156 sustained vowel /a/ phonations with 309 dysphonia measures, select a parsimonious subset using a robust feature selection algorithm, and automatically distinguish the two cohorts (acceptable versus unacceptable) with about 90{\%} overall accuracy. Moreover, we illustrate the potential of the proposed methodology as a probabilistic decision support tool to speech experts to assess a phonation as “acceptable” or “unacceptable.” We envisage the findings of this study being a first step towards improving the effectiveness of an automated rehabilitative speech assessment tool.},
author = {Tsanas, Athanasios and Little, Max A. and Fox, Cynthia and Ramig, Lorraine O.},
doi = {10.1109/TNSRE.2013.2293575},
isbn = {1534-4320},
issn = {15344320},
journal = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
keywords = {Decision support tool,Lee Silverman voice treatment (LSVT),Parkinson's disease (PD),Speech rehabilitation},
number = {1},
pages = {181--190},
pmid = {26271131},
title = {{Objective automatic assessment of rehabilitative speech treatment in Parkinson's disease}},
volume = {22},
year = {2014}
}

@article{Little2007,
abstract = {BACKGROUND Voice disorders affect patients profoundly, and acoustic tools can potentially measure voice function objectively. Disordered sustained vowels exhibit wide-ranging phenomena, from nearly periodic to highly complex, aperiodic vibrations, and increased "breathiness". Modelling and surrogate data studies have shown significant nonlinear and non-Gaussian random properties in these sounds. Nonetheless, existing tools are limited to analysing voices displaying near periodicity, and do not account for this inherent biophysical nonlinearity and non-Gaussian randomness, often using linear signal processing methods insensitive to these properties. They do not directly measure the two main biophysical symptoms of disorder: complex nonlinear aperiodicity, and turbulent, aeroacoustic, non-Gaussian randomness. Often these tools cannot be applied to more severe disordered voices, limiting their clinical usefulness. METHODS This paper introduces two new tools to speech analysis: recurrence and fractal scaling, which overcome the range limitations of existing tools by addressing directly these two symptoms of disorder, together reproducing a "hoarseness" diagram. A simple bootstrapped classifier then uses these two features to distinguish normal from disordered voices. RESULTS On a large database of subjects with a wide variety of voice disorders, these new techniques can distinguish normal from disordered cases, using quadratic discriminant analysis, to overall correct classification performance of 91.8 +/- 2.0{\%}. The true positive classification performance is 95.4 +/- 3.2{\%}, and the true negative performance is 91.5 +/- 2.3{\%} (95{\%} confidence). This is shown to outperform all combinations of the most popular classical tools. CONCLUSION Given the very large number of arbitrary parameters and computational complexity of existing techniques, these new techniques are far simpler and yet achieve clinically useful classification performance using only a basic classification technique. They do so by exploiting the inherent nonlinearity and turbulent randomness in disordered voice signals. They are widely applicable to the whole range of disordered voice phenomena by design. These new measures could therefore be used for a variety of practical clinical purposes.},
archivePrefix = {arXiv},
arxivId = {0707.0086},
author = {Little, Max A and McSharry, Patrick E and Roberts, Stephen J and Costello, Declan A E and Moroz, Irene M},
doi = {10.1186/1475-925X-6-23},
eprint = {0707.0086},
isbn = {1475-925X},
issn = {1475-925X},
journal = {Biomedical engineering online},
pages = {23},
pmid = {17594480},
title = {{Exploiting nonlinear recurrence and fractal scaling properties for voice disorder detection.}},
volume = {6},
year = {2007}
}

@article{Hwang2010,
abstract = {We updated our protein-protein docking benchmark to include complexes that became available since our previous release. As before, we only considered high-resolution complex structures that are nonredundant at the family-family pair level, for which the X-ray or NMR unbound structures of the constituent proteins are also available. Benchmark 4.0 adds 52 new complexes to the 124 cases of Benchmark 3.0, representing an increase of 42{\%}. Thus, benchmark 4.0 provides 176 unbound-unbound cases that can be used for protein-protein docking method development and assessment. Seventeen of the newly added cases are enzyme-inhibitor complexes, and we found no new antigen-antibody complexes. Classifying the new cases according to expected difficulty for protein-protein docking algorithms gives 33 rigid body cases, 11 cases of medium difficulty, and 8 cases that are difficult. Benchmark 4.0 listings and processed structure files are publicly accessible at http://zlab.umassmed.edu/benchmark/.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Hwang, Howook and Vreven, Thom and Janin, Jo{\"{e}}l and Weng, Zhiping},
doi = {10.1002/prot.22830},
eprint = {NIHMS150003},
isbn = {1097-0134 (Electronic)$\backslash$r0887-3585 (Linking)},
issn = {08873585},
journal = {Proteins: Structure, Function and Bioinformatics},
keywords = {Complex structure,Protein complexes,Protein-protein docking,Protein-protein interactions},
number = {15},
pages = {3111--3114},
pmid = {20806234},
title = {{Protein-protein docking benchmark version 4.0}},
volume = {78},
year = {2010}
}

@article{Jimenez2017,
abstract = {Motivation: An important step in structure-based drug design consists in the prediction of druggable binding sites. Several algorithms for detecting binding cavities, those likely to bind to a small drug compound, have been developed over the years by clever exploitation of geometric, chemical and evolutionary features of the protein. Results: Here we present a novel knowledge-based approach that uses state-of-the-art convolutional neural networks, where the algorithm is learned by examples. In total, 7622 proteins from the scPDB database of binding sites have been evaluated using both a distance and a volumetric overlap approach. Our machine-learning based method demonstrates superior performance to two other competitive algorithmic strategies. Availability and implementation: DeepSite is freely available at www.playmolecule.org. Users can submit either a PDB ID or PDB file for pocket detection to our NVIDIA GPU-equipped servers through a WebGL graphical interface.},
author = {Jim{\'{e}}nez, Jos{\'{e}} and Doerr, Stefan and Mart{\'{i}}nez-Rosell, Gerard and Rose, Alexander and {De Fabritiis}, G.},
doi = {10.1093/bioinformatics/btx350},
journal = {Bioinformatics},
keywords = {deep learning,machine learning,structural biology},
mendeley-groups = {ML GRIB/Pocket binding project},
mendeley-tags = {machine learning,structural biology,deep learning},
number = {12},
pages = {1--7},
title = {{DeepSite: Protein binding site predictor using 3D-convolutional neural networks}},
volume = {33},
year = {2017}
}



