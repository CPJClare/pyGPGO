@article{Shahriari2016,
abstract = {—Big data applications are typically associated with systems involving large numbers of users, massive complex software systems, and large-scale heterogeneous computing and storage architectures. The construction of such systems involves many distributed design choices. The end products (e.g., rec-ommendation systems, medical analysis tools, real-time game engines, speech recognizers) thus involves many tunable config-uration parameters. These parameters are often specified and hard-coded into the software by various developers or teams. If optimized jointly, these parameters can result in significant improvements. Bayesian optimization is a powerful tool for the joint optimization of design choices that is gaining great popularity in recent years. It promises greater automation so as to increase both product quality and human productivity. This review paper introduces Bayesian optimization, highlights some of its methodological aspects, and showcases a wide range of applications.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Shahriari, Bobak and Swersky, Kevin and Wang, Ziyu and Adams, Ryan P. and {De Freitas}, Nando},
doi = {10.1109/JPROC.2015.2494218},
eprint = {arXiv:1011.1669v3},
file = {:home/jose/BayesOptLoop (1).pdf:pdf},
isbn = {0018-9219},
issn = {00189219},
journal = {Proceedings of the IEEE},
keywords = {decision making,design of experiments,genomic medicine,optimization,response surface methodology,statistical learning},
number = {1},
pages = {148--175},
pmid = {25246403},
title = {{Taking the human out of the loop: A review of Bayesian optimization}},
volume = {104},
year = {2016}
}
@article{Snoek2012,
abstract = {Machine learning algorithms frequently require careful tuning of model hyperparameters, regularization terms, and optimization parameters. Unfortunately, this tuning is often a" black art" that requires expert experience, unwritten rules of thumb, or sometimes brute-force ... $\backslash$n},
archivePrefix = {arXiv},
arxivId = {arXiv:1206.2944v2},
author = {Snoek, Jasper and Larochelle, Hugo and Adams, Rp},
doi = {2012arXiv1206.2944S},
eprint = {arXiv:1206.2944v2},
file = {:home/jose/1206.2944.pdf:pdf},
isbn = {9781627480031},
issn = {10495258},
journal = {Advances in Neural Information {\ldots}},
pages = {1--9},
pmid = {9377276},
title = {{Practical Bayesian optimization of machine learning algorithms}},
url = {http://papers.nips.cc/paper/4522-practical-bayesian-optimization-of-machine-learning-algorithms},
year = {2012}
}
@article{Bergstra2012,
abstract = {Grid search and manual search are the most widely used strategies for hyper-parameter optimiza-tion. This paper shows empirically and theoretically that randomly chosen trials are more efficient for hyper-parameter optimization than trials on a grid. Empirical evidence comes from a compar-ison with a large previous study that used grid search and manual search to configure neural net-works and deep belief networks. Compared with neural networks configured by a pure grid search, we find that random search over the same domain is able to find models that are as good or better within a small fraction of the computation time. Granting random search the same computational budget, random search finds better models by effectively searching a larger, less promising con-figuration space. Compared with deep belief networks configured by a thoughtful combination of manual search and grid search, purely random search over the same 32-dimensional configuration space found statistically equal performance on four of seven data sets, and superior performance on one of seven. A Gaussian process analysis of the function from hyper-parameters to validation set performance reveals that for most data sets only a few of the hyper-parameters really matter, but that different hyper-parameters are important on different data sets. This phenomenon makes grid search a poor choice for configuring algorithms for new data sets. Our analysis casts some light on why recent " High Throughput " methods achieve surprising success—they appear to search through a large number of hyper-parameters because most hyper-parameters do not matter much. We anticipate that growing interest in large hierarchical models will place an increasing burden on techniques for hyper-parameter optimization; this work shows that random search is a natural base-line against which to judge progress in the development of adaptive (sequential) hyper-parameter optimization algorithms.},
archivePrefix = {arXiv},
arxivId = {1504.05070},
author = {{Bergstra James}, James and {Bengio Yoshua}, Umontrealca},
doi = {10.1162/153244303322533223},
eprint = {1504.05070},
isbn = {1532-4435},
issn = {1532-4435},
journal = {Journal of Machine Learning Research},
keywords = {deep learning,global optimization,model selection,neural networks,response surface modeling},
pages = {281--305},
pmid = {18244602},
title = {{Random Search for Hyper-Parameter Optimization}},
volume = {13},
year = {2012}
}
@misc{SpearmintSnoek2012,
abstract = {Spearmint},
author = {Snoek, Jasper},
title = {Spearmint},
url = {https://github.com/HIPS/Spearmint},
year = {2012}
}
@misc{scikitoptimize,
abstract = {scikit-optimize},
author = {The scikit-optimize team.},
title = {scikit-optimize},
url = {https://github.com/scikit-optimize/scikit-optimize},
year = {2016}
}

@misc{yelpmoe,
abstract = {MOE},
author = {Yelp},
title = {MOE},
url = {https://github.com/Yelp/MOE},
year = {2014}
}

@article{Hernandez-Lobato2014,
abstract = { We propose a novel information-theoretic approach$\backslash$nfor Bayesian optimization called Predictive Entropy$\backslash$nSearch (PES). At each iteration, PES selects the$\backslash$nnext evaluation point that maximizes the expected$\backslash$ninformation gained with respect to the global$\backslash$nmaximum. PES codifies this intractable acquisition$\backslash$nfunction in terms of the expected reduction in the$\backslash$ndifferential entropy of the predictive distribution.$\backslash$nThis reformulation allows PES to obtain$\backslash$napproximations that are both more accurate and$\backslash$nefficient than other alternatives such as Entropy$\backslash$nSearch (ES). Furthermore, PES can easily perform a$\backslash$nfully Bayesian treatment of the model$\backslash$nhyperparameters while ES cannot. We evaluate PES in$\backslash$nboth synthetic and realworld applications, including$\backslash$noptimization problems in machine learning, finance,$\backslash$nbiotechnology, and robotics. We show that the$\backslash$nincreased accuracy of PES leads to significant gains$\backslash$nin optimization performance. },
archivePrefix = {arXiv},
arxivId = {arXiv:1406.2541v1},
author = {Hern{\'{a}}ndez-Lobato, Jos{\'{e}} Miguel and Hoffman, Matthew W and Ghahramani, Zoubin},
eprint = {arXiv:1406.2541v1},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems 28},
pages = {1--9},
title = {{Predictive Entropy Search for Efficient Global Optimization of Black-box Functions}},
url = {https://jmhldotorg.files.wordpress.com/2014/10/pes-final.pdf},
year = {2014}
}

